############################################################################
# Model: Tacotron2 with SSL
# Tokens: Raw characters (English text)
# losses: Transducer
# Training: LJSpeech
# Authors: Georges Abous-Rjeili, Artem Ploujnikov, Yingzhi Wang
# ############################################################################


###################################
# Experiment Parameters and setup #
###################################
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref ./results/tacotron2/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
epochs: 750
keep_checkpoint_interval: 50

###################################
# Progress Samples                #
###################################
# Progress samples are used to monitor the progress
# of an ongoing training session by outputting samples
# of spectrograms, alignments, etc at regular intervals

# Whether to enable progress samples
progress_folder: !ref <output_folder>/progress
progress_archive: !ref <progress_folder>/progress.tar
progress_current: !ref <progress_folder>/current
progress_meta: !ref <progress_folder>/meta.yaml
num_audio_samples: 32
samples_interval: 5

#################################
# Data files and pre-processing #
#################################
data_folder: !PLACEHOLDER # e.g, /localscratch/ljspeech
prepare_save_folder: !ref <data_folder>/prepared
pretrained_model_save_folder: !ref <prepare_save_folder>
freeze_ssl_model: True


train_json: !ref <prepare_save_folder>/train.json
valid_json: !ref <prepare_save_folder>/valid.json
test_json: !ref <prepare_save_folder>/test.json

splits: ["train", "valid"]
split_ratio: [90, 10]

skip_prep: False



################################
# Audio Parameters             #
################################
sample_rate: 22050
audio_dim: 1024

# Feature Extraction
extract_features_batch_size: 32
model_sample_rate: 16000
ssl_model_type: hubert
ssl_model_src: facebook/hubert-large-ll60k
ssl_model_layers: [3]

# Vocoder Parameters
vocoder_src: chaanks/hifigan-continuous-hubert-ll60k-l3-ljspeech-ljspeech
vocoder_available_layers: [3]
vocoder_flat_feats: true
vocoder_model_name: unithifigan-hubert-continuous
vocoder_model_path: !ref <pretrained_model_save_folder>/<vocoder_model_name>


# Token model (pretrained)
ssl_model: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices:
        wavlm: !new:speechbrain.lobes.models.huggingface_transformers.wavlm.WavLM
            source: !ref <ssl_model_src>
            save_path: !ref <pretrained_model_save_folder>
            freeze: !ref <freeze_ssl_model>
            output_all_hiddens: True
        hubert: !new:speechbrain.lobes.models.huggingface_transformers.hubert.HuBERT
            source: !ref <ssl_model_src>
            save_path: !ref <pretrained_model_save_folder>
            freeze: !ref <freeze_ssl_model>
            output_all_hiddens: True

# Label encoder
label_encoder: !new:speechbrain.dataio.encoder.TextEncoder
token_list_file: ./hparams/char_en.txt

# Feature Extraction Options
extract_features_opts:
    dataloader_opts:
        batch_size: !ref <extract_features_batch_size>
        num_workers: !ref <num_workers>
    ssl_model: !ref <ssl_model>
    ssl_model_layers: !ref <ssl_model_layers>
    sample_rate: !ref <sample_rate>
    model_sample_rate: !ref <model_sample_rate>




################################
# Optimization Hyperparameters #
################################
learning_rate: 0.001
weight_decay: 0.000006
batch_size: 64 #minimum 2
num_workers: 8
mask_padding: True
guided_attention_sigma: 0.2
guided_attention_weight: 50.0
guided_attention_weight_half_life: 10.
guided_attention_hard_stop: 50
gate_loss_weight: 1.0

train_dataloader_opts:
  batch_size: !ref <batch_size>
  drop_last: False  #True #False
  shuffle: False
  num_workers: !ref <num_workers>

valid_dataloader_opts:
  batch_size: !ref <batch_size>
  num_workers: !ref <num_workers>

test_dataloader_opts:
  batch_size: !ref <batch_size>
  num_workers: !ref <num_workers>

sample_dataloader_opts:
    batch_size: !ref <batch_size>
    num_workers: !ref <num_workers>

################################
# Model Parameters and model   #
################################
n_symbols: 148 #fixed depending on symbols in textToSequence
symbols_embedding_dim: 512

# Encoder parameters
encoder_kernel_size: 5
encoder_n_convolutions: 3
encoder_embedding_dim: 512

# Decoder parameters
# The number of frames in the target per encoder step
n_frames_per_step: 1
decoder_rnn_dim: 1024
prenet_dim: 256
max_decoder_steps: 1000
gate_threshold: 0.5
p_attention_dropout: 0.1
p_decoder_dropout: 0.1
decoder_no_early_stopping: False

# Attention parameters
attention_rnn_dim: 1024
attention_dim: 128

# Location Layer parameters
attention_location_n_filters: 32
attention_location_kernel_size: 31

# Mel-post processing network parameters
postnet_embedding_dim: 512
postnet_kernel_size: 5
postnet_n_convolutions: 5


#model
model: !new:speechbrain.lobes.models.Tacotron2.Tacotron2
  mask_padding: !ref <mask_padding>
  n_mel_channels: !ref <audio_dim>
  # symbols
  n_symbols: !ref <n_symbols>
  symbols_embedding_dim: !ref <symbols_embedding_dim>
  # encoder
  encoder_kernel_size: !ref <encoder_kernel_size>
  encoder_n_convolutions: !ref <encoder_n_convolutions>
  encoder_embedding_dim: !ref <encoder_embedding_dim>
  # attention
  attention_rnn_dim: !ref <attention_rnn_dim>
  attention_dim: !ref <attention_dim>
  # attention location
  attention_location_n_filters: !ref <attention_location_n_filters>
  attention_location_kernel_size: !ref <attention_location_kernel_size>
  # decoder
  n_frames_per_step: !ref <n_frames_per_step>
  decoder_rnn_dim: !ref <decoder_rnn_dim>
  prenet_dim: !ref <prenet_dim>
  max_decoder_steps: !ref <max_decoder_steps>
  gate_threshold: !ref <gate_threshold>
  p_attention_dropout: !ref <p_attention_dropout>
  p_decoder_dropout: !ref <p_decoder_dropout>
  # postnet
  postnet_embedding_dim: !ref <postnet_embedding_dim>
  postnet_kernel_size: !ref <postnet_kernel_size>
  postnet_n_convolutions: !ref <postnet_n_convolutions>
  decoder_no_early_stopping: !ref <decoder_no_early_stopping>

guided_attention_scheduler: !new:speechbrain.nnet.schedulers.StepScheduler
  initial_value: !ref <guided_attention_weight>
  half_life: !ref <guided_attention_weight_half_life>

criterion: !new:speechbrain.lobes.models.Tacotron2.Loss
  gate_loss_weight: !ref <gate_loss_weight>
  guided_attention_weight: !ref <guided_attention_weight>
  guided_attention_sigma: !ref <guided_attention_sigma>
  guided_attention_scheduler: !ref <guided_attention_scheduler>
  guided_attention_hard_stop: !ref <guided_attention_hard_stop>
  
vocoder: !apply:speechbrain.inference.vocoders.HIFIGAN.from_hparams
    source: !ref <vocoder_src>
    savedir: !ref <vocoder_model_path>ÃŸ

modules:
  model: !ref <model>
  vocoder: !ref <vocoder>

#optimizer
opt_class: !name:torch.optim.Adam
  lr: !ref <learning_rate>
  weight_decay: !ref <weight_decay>

#epoch object
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <epochs>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>

#annealing_function
lr_annealing: !new:speechbrain.nnet.schedulers.IntervalScheduler
  intervals:
    - steps: 6000
      lr: 0.0005
    - steps: 8000
      lr: 0.0003
    - steps: 10000
      lr: 0.0001

#checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>
    scheduler: !ref <lr_annealing>

#infer: !name:speechbrain.lobes.models.Tacotron2.infer

progress_logger: !new:benchmarks.DASB.utils.train_logger.ArchiveTrainLogger
    current_path: !ref <progress_current>
    archive_path: !ref <progress_archive>
    meta_path: !ref <progress_meta>
    epoch_counter: !ref <epoch_counter>

progress_report: !new:benchmarks.DASB.utils.tts.TTSProgressReport
    logger: !ref <progress_logger>
    sample_rate: !ref <model_sample_rate>
    eos_threshold: !ref <gate_threshold>

